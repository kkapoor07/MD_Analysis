{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example: Clustering MD Trajectory Data with KMeans\n",
    "\n",
    "# This notebook demonstrates how to use KMeans clustering to identify distinct conformational states from molecular dynamics simulation data. It uses functions from the `md_analysis_tools` library.\n",
    "\n",
    "# **Workflow:**\n",
    "# 1. Import necessary libraries.\n",
    "# 2. Load pre-processed data suitable for clustering. This could be:\n",
    "#     *   Coordinates from specific atoms.\n",
    "#     *   Principal component projections (output from PCA analysis).\n",
    "#     *   Key distances or dihedral angles.\n",
    "#     *   *(This example will assume we are using PC projections from the PCA example)*\n",
    "# 3. (Optional) Determine a suitable number of clusters (k) using the Elbow method.\n",
    "# 4. Perform KMeans clustering using `perform_kmeans`.\n",
    "# 5. Visualize the clusters (e.g., on a PCA plot).\n",
    "# 6. Find representative frames closest to each cluster centroid using `find_closest_frames_to_centroids`.\n",
    "# 7. (Optional) Save the representative structures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import md_analysis_tools # Our custom library\n",
    "import MDAnalysis as mda\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns # For potentially nicer plotting\n",
    "import os\n",
    "\n",
    "# Import KMeans related tools if needed for elbow plot etc.\n",
    "from sklearn.cluster import KMeans \n",
    "# Optional: For elbow plot visualization - install if needed (`pip install yellowbrick`)\n",
    "# try:\n",
    "#     from yellowbrick.cluster import KElbowVisualizer\n",
    "#     _YELLOWBRICK_AVAILABLE = True\n",
    "# except ImportError:\n",
    "#     _YELLOWBRICK_AVAILABLE = False\n",
    "_YELLOWBRICK_AVAILABLE = False # Keep False if not installing/using\n",
    "\n",
    "# Configure plotting style (optional)\n",
    "plt.style.use('seaborn-v0_8-poster')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 1. Load Data for Clustering\n",
    "\n",
    "# Clustering is often performed on reduced-dimensionality data rather than raw coordinates to focus on significant motions and reduce noise. A common choice is to use the projections onto the first few principal components (PCs) obtained from PCA.\n",
    "\n",
    "# **Assumption:** This notebook assumes you have already run PCA (like in `Example_PCA_Analysis.ipynb`) and saved the projections, or you can calculate them here.\n",
    "\n",
    "# **ACTION:**\n",
    "#   - Specify the number of PCs to use for clustering.\n",
    "#   - Provide the path to the PCA projection data *OR* uncomment and adapt the PCA calculation section if you need to run it first.\n",
    "#   - Define topology/trajectory paths if calculating PCA here *or* if needed later for saving structures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- User Input ---\n",
    "pca_components_to_use = 3 # How many PCs to use for clustering (e.g., 2 or 3)\n",
    "projection_file = None    # Set to path if loading pre-calculated projections, e.g., \"pca_analysis_output/pca_projections.csv\"\n",
    "\n",
    "# --- OR --- Calculate PCA projections here if needed ---\n",
    "# If projection_file is None, we might need to calculate them.\n",
    "# Requires topology and trajectory files.\n",
    "topology_file = \"placeholder.prmtop\" # <-- Needs path if calculating PCA or saving structures\n",
    "trajectory_file = \"placeholder.dcd\"   # <-- Needs path if calculating PCA or saving structures\n",
    "pca_selection = \"name CA and protein\" # Selection used for PCA\n",
    "align_selection = \"name CA and protein\" # Selection used for alignment (or None)\n",
    "output_dir = \"clustering_analysis_output\" # Directory for saving results\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# --- Load/Calculate Data ---\n",
    "data_for_clustering = None\n",
    "pca_result_obj = None # To store PCA object if calculated here\n",
    "\n",
    "if projection_file and os.path.exists(projection_file):\n",
    "    print(f\"Loading pre-calculated projections from: {projection_file}\")\n",
    "    try:\n",
    "        df_projections = pd.read_csv(projection_file)\n",
    "        # Select the first 'pca_components_to_use' columns (assuming they are named PC1, PC2, ...)\n",
    "        pc_cols = [f'PC{i+1}' for i in range(pca_components_to_use)]\n",
    "        if all(col in df_projections.columns for col in pc_cols):\n",
    "             data_for_clustering = df_projections[pc_cols].values\n",
    "             print(f\"Using PC columns: {pc_cols}\")\n",
    "        else:\n",
    "             print(f\"Error: Projection file exists but doesn't contain required columns {pc_cols}.\", file=sys.stderr)\n",
    "             # exit()\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading projection file: {e}\", file=sys.stderr)\n",
    "        # exit()\n",
    "\n",
    "elif topology_file and trajectory_file and os.path.exists(topology_file) and os.path.exists(trajectory_file):\n",
    "    print(\"Projection file not found or specified. Calculating PCA projections now...\")\n",
    "    try:\n",
    "        u = mda.Universe(topology_file, trajectory_file)\n",
    "        print(f\"Universe loaded with {len(u.trajectory)} frames.\")\n",
    "        \n",
    "        pca_result_obj = md_analysis_tools.perform_cartesian_pca(\n",
    "            universe=u,\n",
    "            select=pca_selection,\n",
    "            align=(align_selection is not None),\n",
    "            align_select=align_selection,\n",
    "            n_components=pca_components_to_use \n",
    "        )\n",
    "        \n",
    "        if pca_result_obj:\n",
    "            pca_atoms = u.select_atoms(pca_selection)\n",
    "            data_for_clustering = pca_result_obj.transform(pca_atoms, n_components=pca_components_to_use)\n",
    "            print(f\"PCA calculation and transformation complete.\")\n",
    "            # Optionally save projections\n",
    "            df_projections = pd.DataFrame(data_for_clustering, columns=[f'PC{i+1}' for i in range(pca_components_to_use)])\n",
    "            df_projections.to_csv(os.path.join(output_dir, \"pca_projections_calculated.csv\"), index=False)\n",
    "        else:\n",
    "            print(\"PCA calculation failed during data loading.\", file=sys.stderr)\n",
    "            # exit()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading Universe or running PCA: {e}\", file=sys.stderr)\n",
    "        # exit()\n",
    "else:\n",
    "    print(\"Error: Cannot proceed without either a projection file or valid topology/trajectory files.\", file=sys.stderr)\n",
    "    # exit()\n",
    "\n",
    "# --- Verify Data ---\n",
    "if data_for_clustering is not None:\n",
    "     print(f\"\\nData shape for clustering: {data_for_clustering.shape}\") # Should be (n_frames, n_components_to_use)\n",
    "else:\n",
    "     print(\"\\nClustering cannot proceed due to data loading/calculation errors.\", file=sys.stderr)\n",
    "     # exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 2. Determine Optimal Number of Clusters (k) - Optional\n",
    "\n",
    "# The Elbow method is a common heuristic to find a suitable number of clusters. It involves running KMeans for a range of `k` values and plotting the Sum of Squared Errors (SSE) or \"inertia\". The \"elbow\" point in the plot suggests a good balance between the number of clusters and the variance explained.\n",
    "\n",
    "# We can use `scikit-learn`'s `KMeans` inertia attribute or the `yellowbrick` library for visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Elbow Method ---\n",
    "if data_for_clustering is not None:\n",
    "    sse = []\n",
    "    k_range = range(1, 11) # Test k from 1 to 10\n",
    "\n",
    "    print(\"\\nCalculating SSE for Elbow method...\")\n",
    "    for k in k_range:\n",
    "        kmeans_test = KMeans(\n",
    "            n_clusters=k,\n",
    "            init='k-means++', # Common initialization method\n",
    "            n_init=10,       # Run multiple times with different seeds\n",
    "            random_state=42  # For reproducibility\n",
    "        )\n",
    "        kmeans_test.fit(data_for_clustering)\n",
    "        sse.append(kmeans_test.inertia_) # inertia_ is the SSE\n",
    "\n",
    "    # Plot SSE vs k\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(k_range, sse, marker='o', linestyle='--')\n",
    "    plt.title('Elbow Method for Optimal k')\n",
    "    plt.xlabel('Number of Clusters (k)')\n",
    "    plt.ylabel('Sum of Squared Errors (SSE)')\n",
    "    plt.xticks(k_range)\n",
    "    plt.grid(True, linestyle=':')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, \"kmeans_elbow_plot.png\"), dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "    # --- Optional: Yellowbrick visualization ---\n",
    "    if _YELLOWBRICK_AVAILABLE:\n",
    "        print(\"\\nUsing Yellowbrick KElbowVisualizer...\")\n",
    "        try:\n",
    "            model = KMeans(init='k-means++', n_init=10, random_state=42)\n",
    "            visualizer = KElbowVisualizer(model, k=k_range)\n",
    "            visualizer.fit(data_for_clustering)\n",
    "            visualizer.show(outpath=os.path.join(output_dir, \"kmeans_elbow_yellowbrick.png\"))\n",
    "            # The visualizer might suggest an optimal k based on the elbow or other metrics.\n",
    "            print(f\"(Yellowbrick suggested k: {visualizer.elbow_value_})\") # May be None\n",
    "        except Exception as e:\n",
    "             print(f\"Yellowbrick visualization failed: {e}\", file=sys.stderr)\n",
    "else:\n",
    "    print(\"Skipping Elbow method due to missing data.\")\n",
    "    \n",
    "# --- User Decision ---\n",
    "# Based on the plot, choose a value for k where the SSE decrease starts to level off.\n",
    "optimal_k = 3 # <-- REPLACE with your chosen k value based on the elbow plot\n",
    "\n",
    "print(f\"\\nSelected optimal number of clusters (k): {optimal_k}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 3. Perform KMeans Clustering\n",
    "\n",
    "# Now we use the chosen `optimal_k` and run the `perform_kmeans` function from our library on the prepared data (e.g., PCA projections). We can also choose whether to scale the data (often recommended if the ranges of the PCs differ significantly, although PCA components are often somewhat scaled already).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Run KMeans ---\n",
    "kmeans_model = None\n",
    "labels = None\n",
    "centroids = None\n",
    "data_used = None # Store the data actually used (potentially scaled)\n",
    "\n",
    "if data_for_clustering is not None:\n",
    "    print(f\"\\nRunning KMeans with k={optimal_k}...\")\n",
    "    kmeans_result_tuple = md_analysis_tools.perform_kmeans(\n",
    "        data=data_for_clustering,\n",
    "        n_clusters=optimal_k,\n",
    "        scale_data=False, # Set to True if features (PCs) have very different scales\n",
    "        random_state=42, # For reproducibility\n",
    "        # Pass additional kwargs for scikit-learn's KMeans if needed\n",
    "        # init='k-means++',\n",
    "        # n_init=10\n",
    "    )\n",
    "\n",
    "    if kmeans_result_tuple:\n",
    "        kmeans_model, labels, centroids, data_used = kmeans_result_tuple\n",
    "        print(f\"KMeans finished. Found {len(centroids)} centroids.\")\n",
    "        # Count members in each cluster\n",
    "        from collections import Counter\n",
    "        cluster_counts = Counter(labels)\n",
    "        print(\"Cluster populations:\")\n",
    "        for cluster_id, count in sorted(cluster_counts.items()):\n",
    "             print(f\"  Cluster {cluster_id}: {count} frames\")\n",
    "    else:\n",
    "        print(\"KMeans clustering failed.\", file=sys.stderr)\n",
    "        # exit()\n",
    "else:\n",
    "     print(\"Skipping KMeans clustering due to missing data.\", file=sys.stderr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 4. Visualize Clusters\n",
    "\n",
    "# If clustering was performed on 2D or 3D data (e.g., PC1 vs PC2, or PC1 vs PC2 vs PC3), we can visualize the data points colored by their assigned cluster label. We also plot the cluster centroids.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plot Clusters ---\n",
    "if labels is not None and data_used is not None and centroids is not None:\n",
    "    n_dims = data_used.shape[1]\n",
    "    \n",
    "    if n_dims >= 2:\n",
    "        print(\"\\nVisualizing clusters on PC1 vs PC2...\")\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        scatter = plt.scatter(data_used[:, 0], data_used[:, 1], c=labels, cmap='viridis', s=10, alpha=0.5, label='Data Points')\n",
    "        \n",
    "        # Plot centroids\n",
    "        plt.scatter(centroids[:, 0], centroids[:, 1], marker='X', s=200, c='red', edgecolor='black', label='Centroids')\n",
    "        \n",
    "        plt.title(f'KMeans Clustering Results (k={optimal_k}) on PCA Projections')\n",
    "        plt.xlabel('Principal Component 1')\n",
    "        plt.ylabel('Principal Component 2')\n",
    "        plt.legend()\n",
    "        plt.grid(True, linestyle=':')\n",
    "        plt.gca().set_aspect('equal', adjustable='box')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, \"kmeans_clusters_pc1_pc2.png\"), dpi=300)\n",
    "        plt.show()\n",
    "        \n",
    "        if n_dims >= 3:\n",
    "             # Optional: Add 3D plot (PC1 vs PC2 vs PC3)\n",
    "             print(\"\\nVisualizing clusters on PC1 vs PC2 vs PC3...\")\n",
    "             fig = plt.figure(figsize=(10, 10))\n",
    "             ax = fig.add_subplot(111, projection='3d')\n",
    "             scatter_3d = ax.scatter(data_used[:, 0], data_used[:, 1], data_used[:, 2], c=labels, cmap='viridis', s=10, alpha=0.3)\n",
    "             ax.scatter(centroids[:, 0], centroids[:, 1], centroids[:, 2], marker='X', s=250, c='red', edgecolor='black', label='Centroids')\n",
    "             ax.set_title(f'KMeans Clusters (k={optimal_k}) on PC1-3')\n",
    "             ax.set_xlabel('PC1')\n",
    "             ax.set_ylabel('PC2')\n",
    "             ax.set_zlabel('PC3')\n",
    "             ax.legend()\n",
    "             plt.tight_layout()\n",
    "             plt.savefig(os.path.join(output_dir, \"kmeans_clusters_pc1_pc2_pc3.png\"), dpi=300)\n",
    "             plt.show()\n",
    "\n",
    "    else:\n",
    "        print(\"Visualization skipped: Need at least 2 dimensions for scatter plot.\")\n",
    "\n",
    "else:\n",
    "     print(\"Skipping cluster visualization due to previous errors.\", file=sys.stderr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 5. Find Representative Frames\n",
    "\n",
    "# For each cluster, we want to find the actual frame from the original trajectory that is closest to the cluster centroid (in the space used for clustering, e.g., PCA space). This gives us a representative structure for each conformational state.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Find Representatives ---\n",
    "representative_indices = None\n",
    "\n",
    "if labels is not None and data_used is not None and centroids is not None:\n",
    "    print(\"\\nFinding representative frames closest to centroids...\")\n",
    "    representative_indices = md_analysis_tools.find_closest_frames_to_centroids(\n",
    "        data=data_used, # Use the data that was actually clustered (potentially scaled)\n",
    "        labels=labels,\n",
    "        centroids=centroids\n",
    "    )\n",
    "\n",
    "    if representative_indices:\n",
    "        print(\"\\nRepresentative frame indices (0-based) for each cluster:\")\n",
    "        for cluster_id, frame_idx in enumerate(representative_indices):\n",
    "            if frame_idx is not None:\n",
    "                 print(f\"  Cluster {cluster_id}: Frame {frame_idx}\")\n",
    "            else:\n",
    "                 print(f\"  Cluster {cluster_id}: No representative found (empty cluster?)\")\n",
    "                 \n",
    "        # Optional: Re-plot clusters highlighting representatives\n",
    "        if data_used.shape[1] >= 2:\n",
    "             valid_indices = [idx for idx in representative_indices if idx is not None]\n",
    "             if valid_indices:\n",
    "                  rep_data = data_used[valid_indices]\n",
    "                  plt.figure(figsize=(8, 8))\n",
    "                  plt.scatter(data_used[:, 0], data_used[:, 1], c=labels, cmap='viridis', s=10, alpha=0.3)\n",
    "                  plt.scatter(centroids[:, 0], centroids[:, 1], marker='X', s=200, c='red', edgecolor='black', label='Centroids')\n",
    "                  # Highlight representatives\n",
    "                  plt.scatter(rep_data[:, 0], rep_data[:, 1], marker='o', s=150, c='yellow', edgecolor='black', label='Representatives')\n",
    "                  plt.title(f'Clusters with Representatives (k={optimal_k})')\n",
    "                  plt.xlabel('PC1')\n",
    "                  plt.ylabel('PC2')\n",
    "                  plt.legend()\n",
    "                  plt.grid(True, linestyle=':')\n",
    "                  plt.gca().set_aspect('equal', adjustable='box')\n",
    "                  plt.tight_layout()\n",
    "                  plt.savefig(os.path.join(output_dir, \"kmeans_clusters_representatives.png\"), dpi=300)\n",
    "                  plt.show()\n",
    "             \n",
    "    else:\n",
    "        print(\"Failed to find representative frames.\", file=sys.stderr)\n",
    "\n",
    "else:\n",
    "    print(\"Skipping finding representatives due to previous errors.\", file=sys.stderr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 6. (Optional) Save Representative Structures\n",
    "\n",
    "# If representative frame indices were found, we can load the original trajectory and save these specific frames as PDB files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Save Structures ---\n",
    "if representative_indices:\n",
    "    # Need the original Universe object if it wasn't kept in memory\n",
    "    # Reload if necessary (ensure topology/trajectory_file paths are correct)\n",
    "    try:\n",
    "        if 'u' not in locals() or not isinstance(u, mda.Universe):\n",
    "             print(\"\\nReloading Universe to save structures...\")\n",
    "             if os.path.exists(topology_file) and os.path.exists(trajectory_file):\n",
    "                  u = mda.Universe(topology_file, trajectory_file)\n",
    "             else:\n",
    "                  raise FileNotFoundError(\"Topology/Trajectory files not found for saving structures.\")\n",
    "        \n",
    "        print(\"\\nSaving representative structures...\")\n",
    "        # Select all atoms for saving\n",
    "        all_atoms = u.select_atoms(\"all\")\n",
    "        \n",
    "        for cluster_id, frame_idx in enumerate(representative_indices):\n",
    "            if frame_idx is not None:\n",
    "                 try:\n",
    "                      # Access the specific frame\n",
    "                      u.trajectory[frame_idx]\n",
    "                      \n",
    "                      # Define output filename\n",
    "                      pdb_filename = os.path.join(output_dir, f\"representative_cluster_{cluster_id}_frame_{frame_idx}.pdb\")\n",
    "                      \n",
    "                      # Write the PDB file\n",
    "                      all_atoms.write(pdb_filename)\n",
    "                      print(f\"  Saved: {pdb_filename}\")\n",
    "                 except IndexError:\n",
    "                      print(f\"  Error: Frame index {frame_idx} out of bounds for trajectory. Cannot save structure for cluster {cluster_id}.\", file=sys.stderr)\n",
    "                 except Exception as e:\n",
    "                      print(f\"  Error saving structure for cluster {cluster_id} (frame {frame_idx}): {e}\", file=sys.stderr)\n",
    "            else:\n",
    "                 print(f\"  Skipping save for empty cluster {cluster_id}.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during structure saving: {e}\", file=sys.stderr)\n",
    "        \n",
    "else:\n",
    "    print(\"Skipping structure saving as no representative indices were found.\", file=sys.stderr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Conclusion\n",
    "\n",
    "# This notebook demonstrated clustering MD trajectory data (using PCA projections) with KMeans via the `md_analysis_tools` library. We determined an optimal cluster number using the Elbow method, visualized the resulting clusters, and identified representative frames closest to the cluster centroids, saving them as PDB files.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
